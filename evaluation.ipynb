{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocessing import preprocess_df\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "from meteostat import Daily, Hourly, Point\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(df: pd.DataFrame):\n",
    "    start, end = (\n",
    "        df[\"Timestamp\"][df.index[0]],\n",
    "        df.loc[:, \"Timestamp\"][df[df[\"Room\"] == \"Raum 004\"].index[-1]],\n",
    "    )\n",
    "    print(start, end)\n",
    "    start, end = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\"), datetime.strptime(\n",
    "        end, \"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    phoenix = Point(51.98589, 9.25246, 111)\n",
    "    # Get daily data for 2018\n",
    "    data = Hourly(phoenix, start, end + timedelta(weeks=4))\n",
    "    tdf = data.fetch()\n",
    "    tdf = tdf[[\"dwpt\", \"rhum\", \"prcp\", \"wspd\", \"tsun\", \"coco\"]]\n",
    "\n",
    "    tdf = tdf.resample(\"15T\", kind=\"timestamp\").interpolate()\n",
    "\n",
    "    print(tdf.shape, df.shape)\n",
    "\n",
    "    # merge\n",
    "    df.set_index(\"Timestamp\", inplace=True)\n",
    "    df.index = pd.to_datetime(df.index, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    res = df.join(tdf, how=\"left\").drop(columns=[\"WindVelocity\", \"RelativeHumidity\"])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "models = []\n",
    "for i in range(6):\n",
    "    tft = TemporalFusionTransformer.load_from_checkpoint(f\"final_model/room{i+1}.ckpt\")\n",
    "    models.append(tft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-01 00:00:00 2022-04-23 23:45:00\n",
      "(4505, 6) (13248, 20)\n",
      "2022-02-01 00:00:00 2022-02-21 23:45:00\n",
      "(4701, 6) (12096, 20)\n",
      "2022-01-01 00:00:00 2022-01-24 23:45:00\n",
      "(4989, 6) (13824, 20)\n",
      "2022-03-01 00:00:00 2022-03-24 23:45:00\n",
      "(4989, 6) (13824, 20)\n"
     ]
    }
   ],
   "source": [
    "# load test datasets\n",
    "df_april = pd.read_csv(\"data/test/test_april2022.csv\", sep=\",\")\n",
    "df_feb = pd.read_csv(\"data/test/test_feb2022.csv\", sep=\",\")\n",
    "df_jan = pd.read_csv(\"data/test/test_jan2022.csv\", sep=\",\")\n",
    "df_march = pd.read_csv(\"data/test/test_march2022.csv\", sep=\",\")\n",
    "\n",
    "# merge dataset with weather data\n",
    "df_april = merge_data(df_april)\n",
    "df_feb = merge_data(df_feb)\n",
    "df_jan = merge_data(df_jan)\n",
    "df_march = merge_data(df_march)\n",
    "# discretize, impute etc.\n",
    "df_april = preprocess_df(df_april)\n",
    "df_feb = preprocess_df(df_feb)\n",
    "df_jan = preprocess_df(df_jan)\n",
    "df_march = preprocess_df(df_march)\n",
    "\n",
    "test_data = [df_april, df_feb, df_jan, df_march]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "0.6255435\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "0.7948215\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "0.93979174\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "torch.Size([1, 672]) torch.Size([1, 672])\n",
      "0.7467554\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "for test in test_data:\n",
    "    g = test.groupby(\"Room\")\n",
    "    split = [g.get_group(x) for x in g.groups]\n",
    "    rmses_groups = []\n",
    "    predictions_groups = []\n",
    "    for i, room in enumerate(split):\n",
    "        room = room.reset_index()\n",
    "        room[\"time_idx\"] = room.index\n",
    "        max_prediction_length = 4*24*7\n",
    "        max_encoder_length = 3*4*24*7\n",
    "\n",
    "        test = TimeSeriesDataSet(\n",
    "            room,\n",
    "            time_idx=\"time_idx\",\n",
    "            target=\"RoomTemperature\",\n",
    "            group_ids=[\"Room\"],\n",
    "            min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "            max_encoder_length=max_encoder_length,\n",
    "            min_prediction_length=4*24,\n",
    "            max_prediction_length=max_prediction_length,\n",
    "            static_categoricals=[],\n",
    "            time_varying_known_categoricals=[],\n",
    "            time_varying_unknown_reals=[\"RoomTemperature\"],\n",
    "            add_relative_time_idx=True,\n",
    "            add_target_scales=True,\n",
    "            add_encoder_length=True,\n",
    "        )\n",
    "        testset = TimeSeriesDataSet.from_dataset(test, room, predict=True, stop_randomization=True)\n",
    "        batch_size = 64  # set this between 32 to 128\n",
    "        test_dataloader = testset.to_dataloader(train=False, batch_size=batch_size, num_workers=3)\n",
    "        actuals = torch.cat([y[0] for x, y in iter(test_dataloader)])\n",
    "        predictions = models[i].predict(test_dataloader)\n",
    "        print(actuals.shape, predictions.shape)\n",
    "        rmse = mean_squared_error(actuals, predictions, squared=False)\n",
    "        rmses_groups.append(rmse)\n",
    "        tdf = pd.DataFrame(predictions.squeeze().numpy(), columns=[\"Prediction\"], index=room[\"index\"][-actuals.shape[1]:])\n",
    "        tdf.reset_index(inplace=True)\n",
    "        tdf = tdf.rename(columns={'index': 'Timestamp'})\n",
    "        tdf[\"Room\"] = f\"Room 00{i+4}\"\n",
    "        tdf = tdf[['Timestamp', 'Room', 'Prediction']]\n",
    "        predictions_groups.append(tdf)\n",
    "    print(np.mean(rmses_groups))\n",
    "    test_preds.append(pd.concat(predictions_groups, axis=0))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, name in zip(test_preds, [\"april\", \"feb\", \"jan\", \"march\"]):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.to_csv(f\"results/2/pred_{name}2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1: 0.960051417350769, 2: 0.9707706570625305\n",
      "1: 1: 0.8535737991333008, 2: 0.6850458383560181\n",
      "2: 1: 0.9124508500099182, 2: 0.6031814813613892\n",
      "3: 1: 0.6960859298706055, 2: 0.7537965774536133\n",
      "4: 1: 0.7254562973976135, 2: 0.6786210536956787\n",
      "5: 1: 1.02659273147583, 2: 1.0201828479766846\n"
     ]
    }
   ],
   "source": [
    "for k, v in scores.items():\n",
    "    print(f\"{k}: 1: {np.mean(v[0])}, 2: {np.mean(v[1])}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cfc55a9e681aa44174671c797b89b3576acc1b81dbd9e903659548f8e108e52"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
