{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_profiling\n",
    "from visualize import visualize_rooms\n",
    "from preprocessing import preprocess_df, merge_data\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from model import train_model\n",
    "from autots import AutoTS\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning AverageValueNaive\n",
      "Beginning SectionalMotif\n",
      "Beginning NVAR\n",
      "Beginning Datepart RandomForest\n",
      "Beginning Datepart SVM\n",
      "Beginning Theta\n",
      "Beginning ARIMA\n",
      "Beginning Multivariate KNN\n",
      "Beginning MLP\n",
      "Beginning KerasRNN\n",
      "tensorflow failed with: ModuleNotFoundError(\"No module named 'keras'\")\n",
      "Beginning KerasCNN\n",
      "tensorflow CNN failed with: ModuleNotFoundError(\"No module named 'keras'\")\n",
      "Beginning GluonTS\n",
      "gluonts failed with: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.')\n",
      "Beginning Prophet\n",
      "prophet failed with: ModuleNotFoundError(\"No module named 'prophet'\")\n",
      "Beginning AverageValueNaive\n",
      "Beginning SectionalMotif\n",
      "Beginning NVAR\n",
      "Beginning Datepart RandomForest\n",
      "Beginning Datepart SVM\n",
      "Beginning Theta\n",
      "Beginning ARIMA\n",
      "Beginning Multivariate KNN\n",
      "Beginning MLP\n",
      "Beginning KerasRNN\n",
      "tensorflow failed with: ModuleNotFoundError(\"No module named 'keras'\")\n",
      "Beginning KerasCNN\n",
      "tensorflow CNN failed with: ModuleNotFoundError(\"No module named 'keras'\")\n",
      "Beginning GluonTS\n",
      "gluonts failed with: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.')\n",
      "Beginning Prophet\n",
      "prophet failed with: ModuleNotFoundError(\"No module named 'prophet'\")\n",
      "Beginning AverageValueNaive\n",
      "Beginning SectionalMotif\n",
      "Beginning NVAR\n",
      "Beginning Datepart RandomForest\n",
      "Beginning Datepart SVM\n",
      "Beginning Theta\n",
      "Beginning ARIMA\n",
      "Beginning Multivariate KNN\n",
      "Beginning MLP\n",
      "Beginning KerasRNN\n",
      "tensorflow failed with: ModuleNotFoundError(\"No module named 'keras'\")\n",
      "Beginning KerasCNN\n",
      "tensorflow CNN failed with: ModuleNotFoundError(\"No module named 'keras'\")\n",
      "Beginning GluonTS\n",
      "gluonts failed with: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.')\n",
      "Beginning Prophet\n",
      "prophet failed with: ModuleNotFoundError(\"No module named 'prophet'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'version': '0.4.0',\n",
       " 'platform': 'Windows-10-10.0.22000-SP0',\n",
       " 'node': 'DESKTOP-B65106C',\n",
       " 'python_version': '3.9.12',\n",
       " 'n_jobs': 'auto',\n",
       " 'times': 3,\n",
       " 'avg_naive_runtime': 0.9673456000000442,\n",
       " 'sect_motif_runtime': 5.643858600000082,\n",
       " 'nvar_runtime': 7.42452579999978,\n",
       " 'datepart_trees_runtime': 6.63874289999967,\n",
       " 'datepart_svm_runtime': 7.415726366666907,\n",
       " 'multivariate_knn_runtime': 10.48839503333329,\n",
       " 'theta_runtime': 13.621469433333308,\n",
       " 'arima_runtime': 12.857076733333392,\n",
       " 'sklearn_mlp_runtime': 1.5788178333332326,\n",
       " 'total_runtime': 66.6359582999997,\n",
       " 'tensorflow_rnn_runtime': 0.0,\n",
       " 'tensorflow_cnn_runtime': 0.0,\n",
       " 'gluonts_runtime': 0.0,\n",
       " 'prophet_runtime': 0.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autots.evaluator.benchmark import Benchmark\n",
    "bench = Benchmark()\n",
    "bench.run(n_jobs=\"auto\", times=3)\n",
    "bench.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DtypeWarning: Columns (11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140253, 6) (848411, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n"
     ]
    }
   ],
   "source": [
    "# load dataset and preprocess\n",
    "df = pd.read_csv(\"data/train/data.csv\", sep=\";\")\n",
    "# merge dataset with weather data\n",
    "df = merge_data(df)\n",
    "# discretize, impute etc.\n",
    "df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = df.copy()\n",
    "df_ts = df_ts.reset_index().rename(columns={'index':'timestamp'})\n",
    "print(df_ts.head(2))\n",
    "metric_weighting = {\n",
    "    'smape_weighting': 5,\n",
    "    'mae_weighting': 2,\n",
    "    'rmse_weighting': 2,\n",
    "    'made_weighting': 0.5,\n",
    "    'mage_weighting': 1,\n",
    "    'mle_weighting': 0,\n",
    "    'imle_weighting': 0,\n",
    "    'spl_weighting': 3,\n",
    "    'containment_weighting': 0,\n",
    "    'contour_weighting': 1,\n",
    "    'runtime_weighting': 0.05,\n",
    "}\n",
    "# Evaluate different simple time series models\n",
    "model = AutoTS(\n",
    "    forecast_length=96,\n",
    "    frequency='infer',\n",
    "    model_list=\"multivariate\",\n",
    "    transformer_list=\"all\",\n",
    "    ensemble='simple',\n",
    "    max_generations=20,\n",
    "    num_validations=2,\n",
    "    metric_weighting=metric_weighting,\n",
    "    n_jobs='auto',\n",
    "    holiday_country=\"DE\",\n",
    "    validation_method=\"backwards\"\n",
    ")\n",
    "\n",
    "model.fit(df_ts, date_col='timestamp', value_col='RoomTemperature', id_col=\"Room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 6.12824612\n",
      "Iteration 2, loss = 0.29221966\n",
      "Iteration 3, loss = 0.22378249\n",
      "Iteration 4, loss = 0.19912970\n",
      "Iteration 5, loss = 0.18698228\n",
      "Iteration 6, loss = 0.17930021\n",
      "Iteration 7, loss = 0.17403015\n",
      "Iteration 8, loss = 0.17046356\n",
      "Iteration 9, loss = 0.16748388\n",
      "Iteration 10, loss = 0.16504452\n",
      "Iteration 11, loss = 0.16319854\n",
      "Iteration 12, loss = 0.16072004\n",
      "Iteration 13, loss = 0.15939499\n",
      "Iteration 14, loss = 0.15775809\n",
      "Iteration 15, loss = 0.15660681\n",
      "Iteration 16, loss = 0.15510819\n",
      "Iteration 17, loss = 0.15401781\n",
      "Iteration 18, loss = 0.15316896\n",
      "Iteration 19, loss = 0.15219019\n",
      "Iteration 20, loss = 0.15147132\n",
      "Iteration 21, loss = 0.15073778\n",
      "Iteration 22, loss = 0.14995406\n",
      "Iteration 23, loss = 0.14918801\n",
      "Iteration 24, loss = 0.14902369\n",
      "Iteration 25, loss = 0.14813625\n",
      "Iteration 26, loss = 0.14774502\n",
      "Iteration 27, loss = 0.14762732\n",
      "Iteration 28, loss = 0.14694145\n",
      "Iteration 29, loss = 0.14662518\n",
      "Iteration 30, loss = 0.14629679\n",
      "Iteration 31, loss = 0.14596139\n",
      "Iteration 32, loss = 0.14551114\n",
      "Iteration 33, loss = 0.14505207\n",
      "Iteration 34, loss = 0.14462658\n",
      "Iteration 35, loss = 0.14412622\n",
      "Iteration 36, loss = 0.14412514\n",
      "Iteration 37, loss = 0.14327744\n",
      "Iteration 38, loss = 0.14329096\n",
      "Iteration 39, loss = 0.14286338\n",
      "Iteration 40, loss = 0.14281780\n",
      "Iteration 41, loss = 0.14244252\n",
      "Iteration 42, loss = 0.14226267\n",
      "Iteration 43, loss = 0.14190885\n",
      "Iteration 44, loss = 0.14158535\n",
      "Iteration 45, loss = 0.14132296\n",
      "Iteration 46, loss = 0.14104964\n",
      "Iteration 47, loss = 0.14077538\n",
      "Iteration 48, loss = 0.14057699\n",
      "Iteration 49, loss = 0.14040517\n",
      "Iteration 50, loss = 0.14006745\n",
      "Iteration 51, loss = 0.14002283\n",
      "Iteration 52, loss = 0.13982525\n",
      "Iteration 53, loss = 0.13946966\n",
      "Iteration 54, loss = 0.13916454\n",
      "Iteration 55, loss = 0.13888323\n",
      "Iteration 56, loss = 0.13846886\n",
      "Iteration 57, loss = 0.13845855\n",
      "Iteration 58, loss = 0.13830348\n",
      "Iteration 59, loss = 0.13792949\n",
      "Iteration 60, loss = 0.13745938\n",
      "Iteration 61, loss = 0.13732344\n",
      "Iteration 62, loss = 0.13734711\n",
      "Iteration 63, loss = 0.13683374\n",
      "Iteration 64, loss = 0.13692648\n",
      "Iteration 65, loss = 0.13663028\n",
      "Iteration 66, loss = 0.13653274\n",
      "Iteration 67, loss = 0.13627674\n",
      "Iteration 68, loss = 0.13616781\n",
      "Iteration 69, loss = 0.13640610\n",
      "Iteration 70, loss = 0.13606430\n",
      "Iteration 71, loss = 0.13587127\n",
      "Iteration 72, loss = 0.13577724\n",
      "Iteration 73, loss = 0.13574867\n",
      "Iteration 74, loss = 0.13547662\n",
      "Iteration 75, loss = 0.13534876\n",
      "Iteration 76, loss = 0.13504136\n",
      "Iteration 77, loss = 0.13512400\n",
      "Iteration 78, loss = 0.13492428\n",
      "Iteration 79, loss = 0.13480345\n",
      "Iteration 80, loss = 0.13481104\n",
      "Iteration 81, loss = 0.13429594\n",
      "Iteration 82, loss = 0.13466325\n",
      "Iteration 83, loss = 0.13439917\n",
      "Iteration 84, loss = 0.13419708\n",
      "Iteration 85, loss = 0.13414520\n",
      "Iteration 86, loss = 0.13434202\n",
      "Iteration 87, loss = 0.13368090\n",
      "Iteration 88, loss = 0.13402829\n",
      "Iteration 89, loss = 0.13378527\n",
      "Iteration 90, loss = 0.13396763\n",
      "Iteration 91, loss = 0.13341164\n",
      "Iteration 92, loss = 0.13324550\n",
      "Iteration 93, loss = 0.13326926\n",
      "Iteration 94, loss = 0.13333582\n",
      "Iteration 95, loss = 0.13302494\n",
      "Iteration 96, loss = 0.13293188\n",
      "Iteration 97, loss = 0.13307401\n",
      "Iteration 98, loss = 0.13290231\n",
      "Iteration 99, loss = 0.13272151\n",
      "Iteration 100, loss = 0.13287867\n",
      "Iteration 101, loss = 0.13264566\n",
      "Iteration 102, loss = 0.13257250\n",
      "Iteration 103, loss = 0.13230611\n",
      "Iteration 104, loss = 0.13220230\n",
      "Iteration 105, loss = 0.13266766\n",
      "Iteration 106, loss = 0.13220810\n",
      "Iteration 107, loss = 0.13245605\n",
      "Iteration 108, loss = 0.13228380\n",
      "Iteration 109, loss = 0.13234808\n",
      "Iteration 110, loss = 0.13156041\n",
      "Iteration 111, loss = 0.13214117\n",
      "Iteration 112, loss = 0.13130758\n",
      "Iteration 113, loss = 0.13193489\n",
      "Iteration 114, loss = 0.13148438\n",
      "Iteration 115, loss = 0.13176713\n",
      "Iteration 116, loss = 0.13160334\n",
      "Iteration 117, loss = 0.13134961\n",
      "Iteration 118, loss = 0.13162341\n",
      "Iteration 119, loss = 0.13141097\n",
      "Iteration 120, loss = 0.13105583\n",
      "Iteration 121, loss = 0.13146776\n",
      "Iteration 122, loss = 0.13105190\n",
      "Iteration 123, loss = 0.13125358\n",
      "Iteration 124, loss = 0.13093520\n",
      "Iteration 125, loss = 0.13092907\n",
      "Iteration 126, loss = 0.13089363\n",
      "Iteration 127, loss = 0.13112952\n",
      "Iteration 128, loss = 0.13098880\n",
      "Iteration 129, loss = 0.13067798\n",
      "Iteration 130, loss = 0.13089026\n",
      "Iteration 131, loss = 0.13067292\n",
      "Iteration 132, loss = 0.13099822\n",
      "Iteration 133, loss = 0.13079052\n",
      "Iteration 134, loss = 0.13034692\n",
      "Iteration 135, loss = 0.13089147\n",
      "Iteration 136, loss = 0.13076720\n",
      "Iteration 137, loss = 0.13079033\n",
      "Iteration 138, loss = 0.13062064\n",
      "Iteration 139, loss = 0.13096772\n",
      "Iteration 140, loss = 0.13032898\n",
      "Iteration 141, loss = 0.13072261\n",
      "Iteration 142, loss = 0.13054258\n",
      "Iteration 143, loss = 0.13032159\n",
      "Iteration 144, loss = 0.13012376\n",
      "Iteration 145, loss = 0.13032402\n",
      "Iteration 146, loss = 0.13051534\n",
      "Iteration 147, loss = 0.13032730\n",
      "Iteration 148, loss = 0.13030290\n",
      "Iteration 149, loss = 0.13016356\n",
      "Iteration 150, loss = 0.13006716\n",
      "Iteration 151, loss = 0.13023706\n",
      "Iteration 152, loss = 0.13022818\n",
      "Iteration 153, loss = 0.12984949\n",
      "Iteration 154, loss = 0.13029278\n",
      "Iteration 155, loss = 0.13004991\n",
      "Iteration 156, loss = 0.12994841\n",
      "Iteration 157, loss = 0.13009788\n",
      "Iteration 158, loss = 0.12993733\n",
      "Iteration 159, loss = 0.13008294\n",
      "Iteration 160, loss = 0.12952163\n",
      "Iteration 161, loss = 0.12974392\n",
      "Iteration 162, loss = 0.12957501\n",
      "Iteration 163, loss = 0.12987019\n",
      "Iteration 164, loss = 0.12962584\n",
      "Iteration 165, loss = 0.12971258\n",
      "Iteration 166, loss = 0.13000174\n",
      "Iteration 167, loss = 0.12952641\n",
      "Iteration 168, loss = 0.12986596\n",
      "Iteration 169, loss = 0.12947175\n",
      "Iteration 170, loss = 0.12968481\n",
      "Iteration 171, loss = 0.12939663\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#roomfour = df[df[\"Room\"]==\"Raum 004\"]\n",
    "#model=ETSModel(roomfour)\n",
    "#fit=model.fit(maxiter=1000)\n",
    "#X=df_ts[:,:-1]\n",
    "#y=df_ts[:,-1]\n",
    "#print(df.index)\n",
    "#df=df.index\n",
    "\n",
    "df_ts = df.copy()\n",
    "df_ts = df_ts.reset_index().rename(columns={'index':'timestamp'})\n",
    "X,y=df_ts.drop(['RoomTemperature'], axis=1), df_ts['RoomTemperature']\n",
    "X['timestamp']=[(int(elem.timestamp()))%7 for elem in X['timestamp']]\n",
    "model=MLPRegressor(random_state=1, max_iter=300,verbose=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532465699366784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"df_test = pd.read_csv(\"data/test/test_feb2022.csv\", sep=\",\")\n",
    "df_test = merge_data(df_test)\n",
    "# discretize, impute etc.\n",
    "df_test = preprocess_df(df_test)\n",
    "df_test_ts = df_test.copy()\n",
    "df_test_ts = df_test_ts.reset_index().rename(columns={'index':'timestamp'})\n",
    "X_test,y_test=df_test_ts.drop(['RoomTemperature'], axis=1), df_test_ts['RoomTemperature']\n",
    "X_test['timestamp']=[(int(elem.timestamp()))%7 for elem in X_test['timestamp']]\n",
    "\"\"\"\n",
    "rms = mean_squared_error(y, model.predict(X), squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train your model then:\n",
    "# set n=1 if you only want your best model\n",
    "model.export_template(\"my_models.csv\", models='best', n=15, max_per_model_class=3)\n",
    "\n",
    "# later on a new session\n",
    "# you can set `max_generations=0` in model, and then it will only attempt the imported models\n",
    "# model = model.import_template(\"my_models.csv\", method='only')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a2bf5c915fa092a6c93bd18fc1b38f3d48b36f64db4e1baffc8c1df036645e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hackathon-phoenix')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
